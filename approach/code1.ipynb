{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir=r'D:\\amazonml\\student_resource 3\\dataset\\train.csv'\n",
    "df=pd.read_csv(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_link</th>\n",
       "      <th>group_id</th>\n",
       "      <th>entity_name</th>\n",
       "      <th>entity_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://m.media-amazon.com/images/I/61I9XdN6OF...</td>\n",
       "      <td>748919</td>\n",
       "      <td>item_weight</td>\n",
       "      <td>500.0 gram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://m.media-amazon.com/images/I/71gSRbyXmo...</td>\n",
       "      <td>916768</td>\n",
       "      <td>item_volume</td>\n",
       "      <td>1.0 cup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://m.media-amazon.com/images/I/61BZ4zrjZX...</td>\n",
       "      <td>459516</td>\n",
       "      <td>item_weight</td>\n",
       "      <td>0.709 gram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://m.media-amazon.com/images/I/612mrlqiI4...</td>\n",
       "      <td>459516</td>\n",
       "      <td>item_weight</td>\n",
       "      <td>0.709 gram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://m.media-amazon.com/images/I/617Tl40LOX...</td>\n",
       "      <td>731432</td>\n",
       "      <td>item_weight</td>\n",
       "      <td>1400 milligram</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_link  group_id  entity_name  \\\n",
       "0  https://m.media-amazon.com/images/I/61I9XdN6OF...    748919  item_weight   \n",
       "1  https://m.media-amazon.com/images/I/71gSRbyXmo...    916768  item_volume   \n",
       "2  https://m.media-amazon.com/images/I/61BZ4zrjZX...    459516  item_weight   \n",
       "3  https://m.media-amazon.com/images/I/612mrlqiI4...    459516  item_weight   \n",
       "4  https://m.media-amazon.com/images/I/617Tl40LOX...    731432  item_weight   \n",
       "\n",
       "     entity_value  \n",
       "0      500.0 gram  \n",
       "1         1.0 cup  \n",
       "2      0.709 gram  \n",
       "3      0.709 gram  \n",
       "4  1400 milligram  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "group_id\n",
       "459516    9458\n",
       "752266    9063\n",
       "281678    6137\n",
       "308856    5437\n",
       "731432    4741\n",
       "          ... \n",
       "997333       2\n",
       "656506       2\n",
       "314298       2\n",
       "178031       1\n",
       "226428       1\n",
       "Name: count, Length: 750, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['group_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "entity_name\n",
       "item_weight                      102786\n",
       "depth                             45127\n",
       "width                             44183\n",
       "height                            43597\n",
       "voltage                            9466\n",
       "wattage                            7755\n",
       "item_volume                        7682\n",
       "maximum_weight_recommendation      3263\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['entity_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import urllib\n",
    "import time\n",
    "\n",
    "def create_placeholder_image(image_save_path):\n",
    "    from PIL import Image  \n",
    "    try:\n",
    "        placeholder_image = Image.new('RGB', (100, 100), color='black')\n",
    "        placeholder_image.save(image_save_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating placeholder image: {e}\")\n",
    "        return\n",
    "\n",
    "def download_image(image_link, save_folder, retries=3, delay=3):\n",
    "    if not isinstance(image_link, str):\n",
    "        print(\"Invalid image link:\", image_link)\n",
    "        return\n",
    "\n",
    "    # Ensure the directory exists\n",
    "    if not os.path.exists(save_folder):\n",
    "        os.makedirs(save_folder)\n",
    "        print(f\"Directory {save_folder} created.\")\n",
    "\n",
    "    filename = Path(image_link).name\n",
    "    image_save_path = os.path.join(save_folder, filename)\n",
    "\n",
    "    if os.path.exists(image_save_path):\n",
    "        print(f\"Image already exists: {image_save_path}\")\n",
    "        return\n",
    "\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            print(f\"Attempting to download image: {image_link}, attempt {attempt + 1}\")\n",
    "            urllib.request.urlretrieve(image_link, image_save_path)\n",
    "            print(f\"Image successfully downloaded: {image_save_path}\")\n",
    "            return\n",
    "        except Exception as e:\n",
    "            print(f\"Download failed on attempt {attempt + 1}: {e}\")\n",
    "            time.sleep(delay)\n",
    "    \n",
    "    print(f\"Failed to download image after {retries} attempts. Creating placeholder image.\")\n",
    "    create_placeholder_image(image_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image already exists: images\\71gSRbyXmoL.jpg\n",
      "Image already exists: images\\61BZ4zrjZXL.jpg\n",
      "Image already exists: images\\612mrlqiI4L.jpg\n",
      "Image already exists: images\\617Tl40LOXL.jpg\n",
      "Image already exists: images\\61QsBSE7jgL.jpg\n",
      "Image already exists: images\\81xsq6vf2qL.jpg\n",
      "Image already exists: images\\71DiLRHeZdL.jpg\n",
      "Image already exists: images\\91Cma3RzseL.jpg\n",
      "Image already exists: images\\71jBLhmTNlL.jpg\n",
      "Attempting to download image: https://m.media-amazon.com/images/I/81N73b5khVL.jpg, attempt 1\n",
      "Image successfully downloaded: images\\81N73b5khVL.jpg\n",
      "Attempting to download image: https://m.media-amazon.com/images/I/61oMj2iXOuL.jpg, attempt 1\n",
      "Image successfully downloaded: images\\61oMj2iXOuL.jpg\n",
      "Attempting to download image: https://m.media-amazon.com/images/I/91LPf6OjV9L.jpg, attempt 1\n",
      "Image successfully downloaded: images\\91LPf6OjV9L.jpg\n",
      "Attempting to download image: https://m.media-amazon.com/images/I/81fOxWWWKYL.jpg, attempt 1\n",
      "Image successfully downloaded: images\\81fOxWWWKYL.jpg\n",
      "Attempting to download image: https://m.media-amazon.com/images/I/81dzao1Ob4L.jpg, attempt 1\n",
      "Image successfully downloaded: images\\81dzao1Ob4L.jpg\n",
      "Attempting to download image: https://m.media-amazon.com/images/I/91-iahVGEDL.jpg, attempt 1\n",
      "Image successfully downloaded: images\\91-iahVGEDL.jpg\n",
      "Attempting to download image: https://m.media-amazon.com/images/I/81S2+GnYpTL.jpg, attempt 1\n",
      "Image successfully downloaded: images\\81S2+GnYpTL.jpg\n",
      "Attempting to download image: https://m.media-amazon.com/images/I/81e2YtCOKvL.jpg, attempt 1\n",
      "Image successfully downloaded: images\\81e2YtCOKvL.jpg\n",
      "Attempting to download image: https://m.media-amazon.com/images/I/81RNsNEM1EL.jpg, attempt 1\n",
      "Image successfully downloaded: images\\81RNsNEM1EL.jpg\n",
      "Attempting to download image: https://m.media-amazon.com/images/I/91prZeizZnL.jpg, attempt 1\n",
      "Image successfully downloaded: images\\91prZeizZnL.jpg\n",
      "Attempting to download image: https://m.media-amazon.com/images/I/31EvJszFVfL.jpg, attempt 1\n",
      "Image successfully downloaded: images\\31EvJszFVfL.jpg\n",
      "Attempting to download image: https://m.media-amazon.com/images/I/61wzlucTREL.jpg, attempt 1\n",
      "Image successfully downloaded: images\\61wzlucTREL.jpg\n",
      "Attempting to download image: https://m.media-amazon.com/images/I/61sQ+qAKr4L.jpg, attempt 1\n",
      "Image successfully downloaded: images\\61sQ+qAKr4L.jpg\n",
      "Attempting to download image: https://m.media-amazon.com/images/I/81x77l2T5NL.jpg, attempt 1\n",
      "Image successfully downloaded: images\\81x77l2T5NL.jpg\n",
      "Attempting to download image: https://m.media-amazon.com/images/I/71nywfWZUwL.jpg, attempt 1\n",
      "Image successfully downloaded: images\\71nywfWZUwL.jpg\n",
      "Image already exists: images\\71nywfWZUwL.jpg\n",
      "Attempting to download image: https://m.media-amazon.com/images/I/51WsuKKAVrL.jpg, attempt 1\n",
      "Image successfully downloaded: images\\51WsuKKAVrL.jpg\n",
      "Attempting to download image: https://m.media-amazon.com/images/I/61XGDKap+JL.jpg, attempt 1\n",
      "Image successfully downloaded: images\\61XGDKap+JL.jpg\n",
      "Attempting to download image: https://m.media-amazon.com/images/I/715vVcWJxGL.jpg, attempt 1\n",
      "Image successfully downloaded: images\\715vVcWJxGL.jpg\n",
      "Attempting to download image: https://m.media-amazon.com/images/I/613v+2W4UwL.jpg, attempt 1\n",
      "Image successfully downloaded: images\\613v+2W4UwL.jpg\n",
      "Attempting to download image: https://m.media-amazon.com/images/I/71+fn9TWQmL.jpg, attempt 1\n",
      "Image successfully downloaded: images\\71+fn9TWQmL.jpg\n",
      "Attempting to download image: https://m.media-amazon.com/images/I/71aKgRRQ2wL.jpg, attempt 1\n",
      "Image successfully downloaded: images\\71aKgRRQ2wL.jpg\n",
      "Attempting to download image: https://m.media-amazon.com/images/I/71rKXZJrh4L.jpg, attempt 1\n",
      "Image successfully downloaded: images\\71rKXZJrh4L.jpg\n",
      "Attempting to download image: https://m.media-amazon.com/images/I/71D824lbRvL.jpg, attempt 1\n",
      "Image successfully downloaded: images\\71D824lbRvL.jpg\n",
      "Attempting to download image: https://m.media-amazon.com/images/I/71004c9tzfL.jpg, attempt 1\n",
      "Image successfully downloaded: images\\71004c9tzfL.jpg\n",
      "Attempting to download image: https://m.media-amazon.com/images/I/51bQPPtMqYL.jpg, attempt 1\n",
      "Image successfully downloaded: images\\51bQPPtMqYL.jpg\n",
      "Attempting to download image: https://m.media-amazon.com/images/I/61o2ntPNNgL.jpg, attempt 1\n",
      "Image successfully downloaded: images\\61o2ntPNNgL.jpg\n",
      "Image already exists: images\\61o2ntPNNgL.jpg\n",
      "Attempting to download image: https://m.media-amazon.com/images/I/71IUuTJ8QwL.jpg, attempt 1\n",
      "Image successfully downloaded: images\\71IUuTJ8QwL.jpg\n",
      "Attempting to download image: https://m.media-amazon.com/images/I/915JHkwtcrL.jpg, attempt 1\n",
      "Image successfully downloaded: images\\915JHkwtcrL.jpg\n",
      "Attempting to download image: https://m.media-amazon.com/images/I/71cjrYndwIL.jpg, attempt 1\n",
      "Image successfully downloaded: images\\71cjrYndwIL.jpg\n",
      "Attempting to download image: https://m.media-amazon.com/images/I/81hnk2WXO3L.jpg, attempt 1\n",
      "Image successfully downloaded: images\\81hnk2WXO3L.jpg\n",
      "Attempting to download image: https://m.media-amazon.com/images/I/61HXgujoxpL.jpg, attempt 1\n",
      "Image successfully downloaded: images\\61HXgujoxpL.jpg\n",
      "Attempting to download image: https://m.media-amazon.com/images/I/613G8GOyLSL.jpg, attempt 1\n",
      "Image successfully downloaded: images\\613G8GOyLSL.jpg\n",
      "Attempting to download image: https://m.media-amazon.com/images/I/71YyZ2iPyZL.jpg, attempt 1\n",
      "Image successfully downloaded: images\\71YyZ2iPyZL.jpg\n",
      "Attempting to download image: https://m.media-amazon.com/images/I/81K3JwUCnQL.jpg, attempt 1\n",
      "Image successfully downloaded: images\\81K3JwUCnQL.jpg\n",
      "Attempting to download image: https://m.media-amazon.com/images/I/41wvffSxB4L.jpg, attempt 1\n",
      "Image successfully downloaded: images\\41wvffSxB4L.jpg\n",
      "Attempting to download image: https://m.media-amazon.com/images/I/91cErO-KbLL.jpg, attempt 1\n",
      "Image successfully downloaded: images\\91cErO-KbLL.jpg\n",
      "Attempting to download image: https://m.media-amazon.com/images/I/817vo3DcCNL.jpg, attempt 1\n",
      "Image successfully downloaded: images\\817vo3DcCNL.jpg\n",
      "Attempting to download image: https://m.media-amazon.com/images/I/61AHQ35poHL.jpg, attempt 1\n",
      "Image successfully downloaded: images\\61AHQ35poHL.jpg\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,50):\n",
    "    download_image(image_link=df['image_link'][i],save_folder='images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://m.media-amazon.com/images/I/61I9XdN6OFL.jpg'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['image_link'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(local_image_path):\n",
    "    if not isinstance(local_image_path,str):\n",
    "        print(\"Not a valid path\")\n",
    "    else:\n",
    "        # preprocessing of image should be performed , and image should be stored somewhere in a new directory\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text_from_image(local_image_path):\n",
    "    if not isinstance(local_image_path,str):\n",
    "        print(\"Please give a valid image path\")\n",
    "        # returning nan if the path is invalic\n",
    "        return np.nan\n",
    "    else:\n",
    "        import pytesseract\n",
    "        try:\n",
    "            pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'  # Update this path\n",
    "\n",
    "            from PIL import Image\n",
    "            img=Image.open(local_image_path)\n",
    "            text = pytesseract.image_to_string(img).strip()\n",
    "            if not text:  # Check if the text is empty after stripping\n",
    "                print(f\"No text could be extracted from {local_image_path}\")\n",
    "                # the below code should work for 62mrl\n",
    "                rotated_img=img.rotate(270,expand=True)\n",
    "                text = pytesseract.image_to_string(rotated_img).strip()\n",
    "                if not text:  # Still no text after rotation\n",
    "                    print(f\"No text could be extracted from {local_image_path} even after rotation.\")\n",
    "                    return np.nan\n",
    "                else:\n",
    "                    print(f\"Text extracted after rotating {local_image_path}:\\n{text}\\n\")\n",
    "                    return text\n",
    "            else:\n",
    "                print(f\"Text extracted from {local_image_path}:\\n{text}\\n\")\n",
    "                return text\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {local_image_path}: {e}\")\n",
    "            return np.nan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_all_file_names(directory_path):\n",
    "    \"\"\"\n",
    "    Return all corresponding Image paths of a directory\n",
    "    \"\"\"\n",
    "    if not isinstance(directory_path,str):\n",
    "        print(\"Not a valid path\")\n",
    "        return \n",
    "    try:\n",
    "        for file_name in os.listdir(directory_path):\n",
    "            full_path=os.path.join(directory_path,file_name)\n",
    "            if os.path.isfile(full_path):\n",
    "                yield os.path.join('images',file_name)\n",
    "                \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Directory not found: {directory_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image_text_dataframe(directory_path):\n",
    "    data={\"Image Path\":[],\"Extracted Text\":[]}\n",
    "    for file_name in return_all_file_names(directory_path):\n",
    "        text = read_text_from_image(file_name)  \n",
    "        data[\"Image Path\"].append(file_name)    \n",
    "        data[\"Extracted Text\"].append(text)\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No text could be extracted from images\\612mrlqiI4L.jpg\n",
      "Text extracted after rotating images\\612mrlqiI4L.jpg:\n",
      "COMPOSITION\n",
      "Serving Size: 1 Tablet (0.709 g) | Each serving contains (Approx. Values):\n",
      "\n",
      "‘Kutki Picrorhiza kurroa) rhizome extract ~ 0.5z Biers\n",
      "Kasani (Cichorium endiva) seed extract ~ 1% Bitters\n",
      "Punarnava (Boerhavia diffusa) root extract - 0.07% alkaloids\n",
      "Bhui amla (Phyllanthus amarus) WP extract 0.5% Bitters\n",
      "‘Amla (Phyllanthes emblica) fruit extract ~ 102 Tannins\n",
      "\n",
      "Wissel\n",
      "\n",
      "{IRDA values established as per ICMR 2010 for sedentary Utesye-Hen.\n",
      "STTRDA nt established by ICMR\n",
      "Dopraprite overages of amin ded to compensate las of potency rng storage\n",
      "\n",
      "oie nares: Baking aget 0 Disintgrct INS 12028 NS AS Binder IS 1201, An-sicking agent KS 470\n",
      "(Gi, An-cakng agent DS 51. lazing agent INS 553 Gl. Coating agent NS 46)\n",
      "\n",
      "{CONTAINS PERHITED SYNTHETIC FODO COLOURS DNS 1711S 1726, NS 1726) & NS 17261\n",
      "\n",
      "Recommended Usage 1 Tablet per day or as suggested by the dietian,\n",
      "‘Warning: Consut your physician before using this product you are pregnant. nursing taking any medication or having\n",
      "‘a medical condition.\n",
      "\n",
      "Text extracted from images\\617Tl40LOXL.jpg:\n",
      "HIGH STRENGTH\n",
      "\n",
      "PSYLLIUM\n",
      "\n",
      "HUSK\n",
      "\n",
      "Text extracted from images\\61BZ4zrjZXL.jpg:\n",
      "Serving Size: 1 Tablet (0.709 g) | Each serving contains (Approx. Values):\n",
      "\n",
      "Ingredient Oty. / Serving\n",
      "\n",
      "*PHOSPHOcomplex® Silybin (Sillybum marianum) 200 mg\n",
      "Dandelion (Taraxacum officinale) leaf extract - 10:1 100 mg\n",
      "Kutki (Picrorhiza kurroa)rhizome extract - 0.5% Bitters 50 mg\n",
      "Kasani (Cichorium intybus) seed extract - 1% Bitters 25 mg\n",
      "Punarnava (Boerhavia diffusa) root extract - 0.07% alkaloids 25 mg\n",
      "Bhui amla (Phyllanthus amarus) WP extract - 0.5% Bitters 25 mg\n",
      "Amla (Phyllanthus emblica) fruit extract - 10% Tannins 25 mg\n",
      "Licorice (Glycyrrhiza glabra) root extract - 5% Glycyrrhizin 25 mg\n",
      "Vitamin E 10 mg\n",
      "Piper nigrum fruit extract — 95% Piperine 5mg\n",
      "\n",
      "Nutrients Qty. / Serving\n",
      "\n",
      "Energy 3.04 kcal\n",
      "Carbohydrate 051g\n",
      "(Sugars) 02g\n",
      "Protein 0.049\n",
      "Fat 0.09 g\n",
      "\n",
      "\"ZRDA values established as per ICMR 2010 for sedentary lifestyle-Men.\n",
      "**Z RDA not established by ICMR\n",
      "\n",
      "Text extracted from images\\61I9XdN6OFL.jpg:\n",
      "100% NATUR\n",
      "\n",
      "Text extracted from images\\61QsBSE7jgL.jpg:\n",
      "¢ Naturally-Sourced Psyllium\n",
      "\n",
      "—_\n",
      "\n",
      "* High strength 1400mg\n",
      "per serving\n",
      "Ta a aes ein Laie ss\n",
      "\n",
      "PLANTAGO\n",
      "Co\n",
      "PLANT SEEDs a\n",
      "\n",
      "aoe 365 Vecaul)\n",
      "\n",
      "|\n",
      "a\n",
      "\n",
      "* Suitable for Vegans & Vegetarians\n",
      "\n",
      " ,\n",
      "\n",
      "Horbaach\n",
      "\n",
      "Text extracted from images\\71DiLRHeZdL.jpg:\n",
      "©)\n",
      "\n",
      "VEGAN\n",
      "\n",
      "WO\n",
      "\n",
      "WHEAT\n",
      "FREE\n",
      "\n",
      "SOY\n",
      "\n",
      "psy\n",
      "a: & (a)\n",
      "\n",
      "‘ DAIRY\n",
      "| 365° ECs y ple\n",
      "é\n",
      "FREE FROM\n",
      "\n",
      "PRESERVATIVES\n",
      "\n",
      "Horbaach\n",
      "\n",
      "Text extracted from images\\71gSRbyXmoL.jpg:\n",
      "GEPRAGTES\n",
      "\n",
      "Designed in\n",
      "\n",
      "LIZENZIERTE UND GESCHUTZTE DESIGNS\n",
      "\n",
      "Text extracted from images\\71jBLhmTNlL.jpg:\n",
      "NEW LOOK.\n",
      "SAME Nea LES QUALITY.\n",
      "\n",
      "Mame PSYLLIUM\n",
      "\n",
      "PLANT SEEDS\n",
      "\n",
      "ih Y/\n",
      "\\ 4\n",
      "FOOD\n",
      "SUPPLEMENT oO) CAPSULES a\n",
      "365 VEGAN\n",
      "~— IO) cars LES\n",
      "\n",
      "~ Horbaach\n",
      "\n",
      "Text extracted from images\\81xsq6vf2qL.jpg:\n",
      "Directions: For adults, take two (2) vegan capsules\n",
      "daily, preferably with a meal. Do not exceed stated dose.\n",
      "\n",
      "Nutrition Information\n",
      "\n",
      "Typically Per Daily Dose\n",
      "\n",
      "HIGH ST 0 NSTI it Erte\n",
      "Psyllium Husk Powder 1400mg\n",
      "\n",
      "_PSYLLIUM\n",
      "HUSK\n",
      "\n",
      "PLANTAGO OVATA\n",
      "PLANT SEEDS\n",
      "\n",
      "Ingredients: Psyllium Husk Powder, Capsule Shell (Hy-\n",
      "droxypropylmethylcellulose), Anti-Caking Agents (Mag-\n",
      "nesium Salts of Fatty Acids, Silicon Dioxide).\n",
      "\n",
      "May contain Sesame Seeds & Mustard. For allergens,\n",
      "see the ingredients in bold.\n",
      "\n",
      "Notice: Take this product with 220ml of fluids. Taking\n",
      "this product without adequate fluid may cause the pos-\n",
      "sibility of choking. Do not use this product if you have\n",
      "difficulty swallowing. If you experience chest pain, vom-\n",
      "iting or difficulty in swallowing or breathing after taking\n",
      "this product, seek immediate medical attention. Do not\n",
      "take before sleeping. Fibre products can affect the ab-\n",
      "sorption of many medications. Do not take this product\n",
      "within 1.5 hours of taking medication.\n",
      "\n",
      "Free From: Artificial Colour, Artificial Flavour, Artificial\n",
      "Sweetener, Preservatives.\n",
      "\n",
      "SUITABLE FOR VEGETARIANS & VEGANS\n",
      "\n",
      "HU16790 C\n",
      "\n",
      "3 6 a\n",
      "\n",
      "Horbaach\n",
      "\n",
      "Text extracted from images\\91Cma3RzseL.jpg:\n",
      "Horbaach\n",
      "\n",
      "100%\n",
      "\n",
      "HIGHEST\n",
      "QUALITY\n",
      "\n",
      "HIGH STRENGTH\n",
      "\n",
      "pSYLLIUM\n",
      "HUSK\n",
      "\n",
      "PLANTAGO OVATA\n",
      "PLANT SEEDS\n",
      "\n",
      "Pe\n",
      "\n",
      "Horbaach\n",
      "\n",
      "Error processing images\\extracted_text.csv: cannot identify image file 'images\\\\extracted_text.csv'\n",
      "                   Image Path  \\\n",
      "0      images\\612mrlqiI4L.jpg   \n",
      "1      images\\617Tl40LOXL.jpg   \n",
      "2      images\\61BZ4zrjZXL.jpg   \n",
      "3      images\\61I9XdN6OFL.jpg   \n",
      "4      images\\61QsBSE7jgL.jpg   \n",
      "5      images\\71DiLRHeZdL.jpg   \n",
      "6      images\\71gSRbyXmoL.jpg   \n",
      "7      images\\71jBLhmTNlL.jpg   \n",
      "8      images\\81xsq6vf2qL.jpg   \n",
      "9      images\\91Cma3RzseL.jpg   \n",
      "10  images\\extracted_text.csv   \n",
      "\n",
      "                                       Extracted Text  \n",
      "0   COMPOSITION\\nServing Size: 1 Tablet (0.709 g) ...  \n",
      "1                   HIGH STRENGTH\\n\\nPSYLLIUM\\n\\nHUSK  \n",
      "2   Serving Size: 1 Tablet (0.709 g) | Each servin...  \n",
      "3                                          100% NATUR  \n",
      "4   ¢ Naturally-Sourced Psyllium\\n\\n—_\\n\\n* High s...  \n",
      "5   ©)\\n\\nVEGAN\\n\\nWO\\n\\nWHEAT\\nFREE\\n\\nSOY\\n\\npsy...  \n",
      "6   GEPRAGTES\\n\\nDesigned in\\n\\nLIZENZIERTE UND GE...  \n",
      "7   NEW LOOK.\\nSAME Nea LES QUALITY.\\n\\nMame PSYLL...  \n",
      "8   Directions: For adults, take two (2) vegan cap...  \n",
      "9   Horbaach\\n\\n100%\\n\\nHIGHEST\\nQUALITY\\n\\nHIGH S...  \n",
      "10                                                NaN  \n"
     ]
    }
   ],
   "source": [
    "directory_path = r'D:\\amazonml\\student_resource 3\\approach\\images'\n",
    "\n",
    "# Create the DataFrame\n",
    "df = create_image_text_dataframe(directory_path)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Path</th>\n",
       "      <th>Extracted Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>images\\612mrlqiI4L.jpg</td>\n",
       "      <td>COMPOSITION\\nServing Size: 1 Tablet (0.709 g) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>images\\617Tl40LOXL.jpg</td>\n",
       "      <td>HIGH STRENGTH\\n\\nPSYLLIUM\\n\\nHUSK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>images\\61BZ4zrjZXL.jpg</td>\n",
       "      <td>Serving Size: 1 Tablet (0.709 g) | Each servin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>images\\61I9XdN6OFL.jpg</td>\n",
       "      <td>100% NATUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>images\\61QsBSE7jgL.jpg</td>\n",
       "      <td>¢ Naturally-Sourced Psyllium\\n\\n—_\\n\\n* High s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>images\\71DiLRHeZdL.jpg</td>\n",
       "      <td>©)\\n\\nVEGAN\\n\\nWO\\n\\nWHEAT\\nFREE\\n\\nSOY\\n\\npsy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>images\\71gSRbyXmoL.jpg</td>\n",
       "      <td>GEPRAGTES\\n\\nDesigned in\\n\\nLIZENZIERTE UND GE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>images\\71jBLhmTNlL.jpg</td>\n",
       "      <td>NEW LOOK.\\nSAME Nea LES QUALITY.\\n\\nMame PSYLL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>images\\81xsq6vf2qL.jpg</td>\n",
       "      <td>Directions: For adults, take two (2) vegan cap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>images\\91Cma3RzseL.jpg</td>\n",
       "      <td>Horbaach\\n\\n100%\\n\\nHIGHEST\\nQUALITY\\n\\nHIGH S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>images\\extracted_text.csv</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Image Path  \\\n",
       "0      images\\612mrlqiI4L.jpg   \n",
       "1      images\\617Tl40LOXL.jpg   \n",
       "2      images\\61BZ4zrjZXL.jpg   \n",
       "3      images\\61I9XdN6OFL.jpg   \n",
       "4      images\\61QsBSE7jgL.jpg   \n",
       "5      images\\71DiLRHeZdL.jpg   \n",
       "6      images\\71gSRbyXmoL.jpg   \n",
       "7      images\\71jBLhmTNlL.jpg   \n",
       "8      images\\81xsq6vf2qL.jpg   \n",
       "9      images\\91Cma3RzseL.jpg   \n",
       "10  images\\extracted_text.csv   \n",
       "\n",
       "                                       Extracted Text  \n",
       "0   COMPOSITION\\nServing Size: 1 Tablet (0.709 g) ...  \n",
       "1                   HIGH STRENGTH\\n\\nPSYLLIUM\\n\\nHUSK  \n",
       "2   Serving Size: 1 Tablet (0.709 g) | Each servin...  \n",
       "3                                          100% NATUR  \n",
       "4   ¢ Naturally-Sourced Psyllium\\n\\n—_\\n\\n* High s...  \n",
       "5   ©)\\n\\nVEGAN\\n\\nWO\\n\\nWHEAT\\nFREE\\n\\nSOY\\n\\npsy...  \n",
       "6   GEPRAGTES\\n\\nDesigned in\\n\\nLIZENZIERTE UND GE...  \n",
       "7   NEW LOOK.\\nSAME Nea LES QUALITY.\\n\\nMame PSYLL...  \n",
       "8   Directions: For adults, take two (2) vegan cap...  \n",
       "9   Horbaach\\n\\n100%\\n\\nHIGHEST\\nQUALITY\\n\\nHIGH S...  \n",
       "10                                                NaN  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Path</th>\n",
       "      <th>Extracted Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>images\\612mrlqiI4L.jpg</td>\n",
       "      <td>COMPOSITION\\nServing Size: 1 Tablet (0.709 g) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>images\\617Tl40LOXL.jpg</td>\n",
       "      <td>HIGH STRENGTH\\n\\nPSYLLIUM\\n\\nHUSK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>images\\61BZ4zrjZXL.jpg</td>\n",
       "      <td>Serving Size: 1 Tablet (0.709 g) | Each servin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>images\\61I9XdN6OFL.jpg</td>\n",
       "      <td>100% NATUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>images\\61QsBSE7jgL.jpg</td>\n",
       "      <td>¢ Naturally-Sourced Psyllium\\n\\n—_\\n\\n* High s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>images\\71DiLRHeZdL.jpg</td>\n",
       "      <td>©)\\n\\nVEGAN\\n\\nWO\\n\\nWHEAT\\nFREE\\n\\nSOY\\n\\npsy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>images\\71gSRbyXmoL.jpg</td>\n",
       "      <td>GEPRAGTES\\n\\nDesigned in\\n\\nLIZENZIERTE UND GE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>images\\71jBLhmTNlL.jpg</td>\n",
       "      <td>NEW LOOK.\\nSAME Nea LES QUALITY.\\n\\nMame PSYLL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>images\\81xsq6vf2qL.jpg</td>\n",
       "      <td>Directions: For adults, take two (2) vegan cap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>images\\91Cma3RzseL.jpg</td>\n",
       "      <td>Horbaach\\n\\n100%\\n\\nHIGHEST\\nQUALITY\\n\\nHIGH S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>images\\extracted_text.csv</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Image Path  \\\n",
       "0      images\\612mrlqiI4L.jpg   \n",
       "1      images\\617Tl40LOXL.jpg   \n",
       "2      images\\61BZ4zrjZXL.jpg   \n",
       "3      images\\61I9XdN6OFL.jpg   \n",
       "4      images\\61QsBSE7jgL.jpg   \n",
       "5      images\\71DiLRHeZdL.jpg   \n",
       "6      images\\71gSRbyXmoL.jpg   \n",
       "7      images\\71jBLhmTNlL.jpg   \n",
       "8      images\\81xsq6vf2qL.jpg   \n",
       "9      images\\91Cma3RzseL.jpg   \n",
       "10  images\\extracted_text.csv   \n",
       "\n",
       "                                       Extracted Text  \n",
       "0   COMPOSITION\\nServing Size: 1 Tablet (0.709 g) ...  \n",
       "1                   HIGH STRENGTH\\n\\nPSYLLIUM\\n\\nHUSK  \n",
       "2   Serving Size: 1 Tablet (0.709 g) | Each servin...  \n",
       "3                                          100% NATUR  \n",
       "4   ¢ Naturally-Sourced Psyllium\\n\\n—_\\n\\n* High s...  \n",
       "5   ©)\\n\\nVEGAN\\n\\nWO\\n\\nWHEAT\\nFREE\\n\\nSOY\\n\\npsy...  \n",
       "6   GEPRAGTES\\n\\nDesigned in\\n\\nLIZENZIERTE UND GE...  \n",
       "7   NEW LOOK.\\nSAME Nea LES QUALITY.\\n\\nMame PSYLL...  \n",
       "8   Directions: For adults, take two (2) vegan cap...  \n",
       "9   Horbaach\\n\\n100%\\n\\nHIGHEST\\nQUALITY\\n\\nHIGH S...  \n",
       "10                                                NaN  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df.to_csv('extracted_text2.csv',index=False)\n",
    "except Exception as e:\n",
    "    print(\"Sorry an exception occured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Tablet 0.709 g 200 mg Dandelion 1 0 1 100 mg 0. 5 50 mg Kasani 25 mg Punarnava 0.0 7 25 mg Bhui 0. 5 25 mg Amla 1 0 25 mg Licorice 25 mg Vitamin 10 mg Piper 9 5 5 mg Nutrients 3.04 kcal Carbohydrate 051 g 02 g Protein 0.049 Fat 0 09 g\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def extract_all_numbers_and_words(text):\n",
    "    \"\"\"\n",
    "    args:\n",
    "    :text -> It should be the extracted text column in dataframe, \n",
    "    Here I am trying to keep only the numbers present and next words (Hope, it's accurate)\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return np.nan\n",
    "    \n",
    "    # Regex to match any number followed by one or more words\n",
    "    pattern = r'(\\d+[\\.\\d+]*)\\s*(\\w+)(?:\\s+(\\w+))?'\n",
    "    matches = re.findall(pattern, text)\n",
    "    \n",
    "    if matches:\n",
    "        # Flatten the matches into a string format \"number unit\"\n",
    "        result = []\n",
    "        for match in matches:\n",
    "            result.append(' '.join([part for part in match if part]))  # Join number and following words\n",
    "        return ' '.join(result)  # Return all matches as a single string\n",
    "    return np.nan\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Extracted Text']=df['Extracted Text'].apply(extract_all_numbers_and_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Path</th>\n",
       "      <th>Extracted Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>images\\612mrlqiI4L.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>images\\617Tl40LOXL.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>images\\61BZ4zrjZXL.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>images\\61I9XdN6OFL.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>images\\61QsBSE7jgL.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>images\\71DiLRHeZdL.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>images\\71gSRbyXmoL.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>images\\71jBLhmTNlL.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>images\\81xsq6vf2qL.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>images\\91Cma3RzseL.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>images\\extracted_text.csv</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Image Path  Extracted Text\n",
       "0      images\\612mrlqiI4L.jpg             NaN\n",
       "1      images\\617Tl40LOXL.jpg             NaN\n",
       "2      images\\61BZ4zrjZXL.jpg             NaN\n",
       "3      images\\61I9XdN6OFL.jpg             NaN\n",
       "4      images\\61QsBSE7jgL.jpg             NaN\n",
       "5      images\\71DiLRHeZdL.jpg             NaN\n",
       "6      images\\71gSRbyXmoL.jpg             NaN\n",
       "7      images\\71jBLhmTNlL.jpg             NaN\n",
       "8      images\\81xsq6vf2qL.jpg             NaN\n",
       "9      images\\91Cma3RzseL.jpg             NaN\n",
       "10  images\\extracted_text.csv             NaN"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(r'images\\617Tl40LOXL.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PSYLLIUM\\n\\nHUSK\\nPLANTSEEDS'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=Image.open(r'images\\617Tl40LOXL.jpg')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
